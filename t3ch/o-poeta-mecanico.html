<!DOCTYPE html>
<html>
<style>

		@font-face { font-family: "gohu"; src: url("/gohu.woff") format('woff'); }
		body {
			font-family: 'gohu', monospace;
			max-width: 50em;
			margin: 0 auto;
			color: white;
			background: black;
			line-height: calc(1ex / 0.32);
			margin-top: 3em;
		}
		pre {
			font-family: 'gohu', monospace;
			white-space: pre-wrap;
			line-height: 125%;
      background-color: #111;
      padding: 1em;
		}
		@media only screen and (max-width:768px) {
			body {
				max-width:100%;
			}
		}
		a:link {
			color: #0a0 ;
		}
		a:visited {
			color: #004100 ;
		}
		td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
		span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
		td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
		span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
		.codehilite .hll { background-color: #0000ff }
		.codehilite { background: #000000; }
		.codehilite .c { color: #00ff00 } /* Comment */
		.codehilite .k { color: #ff0000 } /* Keyword */
		.codehilite .ch { color: #00ff00 } /* Comment.Hashbang */
		.codehilite .cm { color: #00ff00 } /* Comment.Multiline */
		.codehilite .cp { color: #e5e5e5 } /* Comment.Preproc */
		.codehilite .cpf { color: #00ff00 } /* Comment.PreprocFile */
		.codehilite .c1 { color: #00ff00 } /* Comment.Single */
		.codehilite .cs { color: #00ff00 } /* Comment.Special */
		.codehilite .kc { color: #ff0000 } /* Keyword.Constant */
		.codehilite .kd { color: #ff0000 } /* Keyword.Declaration */
		.codehilite .kn { color: #ff0000 } /* Keyword.Namespace */
		.codehilite .kp { color: #ff0000 } /* Keyword.Pseudo */
		.codehilite .kr { color: #ff0000 } /* Keyword.Reserved */
		.codehilite .kt { color: #ee82ee } /* Keyword.Type */
		.codehilite .s { color: #87ceeb } /* Literal.String */
		.codehilite .no { color: #7fffd4 } /* Name.Constant */
		.codehilite .nf { color: #ffff00 } /* Name.Function */
		.codehilite .nv { color: #eedd82 } /* Name.Variable */
		.codehilite .sa { color: #87ceeb } /* Literal.String.Affix */
		.codehilite .sb { color: #87ceeb } /* Literal.String.Backtick */
		.codehilite .sc { color: #87ceeb } /* Literal.String.Char */
		.codehilite .dl { color: #87ceeb } /* Literal.String.Delimiter */
		.codehilite .sd { color: #87ceeb } /* Literal.String.Doc */
		.codehilite .s2 { color: #87ceeb } /* Literal.String.Double */
		.codehilite .se { color: #87ceeb } /* Literal.String.Escape */
		.codehilite .sh { color: #87ceeb } /* Literal.String.Heredoc */
		.codehilite .si { color: #87ceeb } /* Literal.String.Interpol */
		.codehilite .sx { color: #87ceeb } /* Literal.String.Other */
		.codehilite .sr { color: #87ceeb } /* Literal.String.Regex */
		.codehilite .s1 { color: #87ceeb } /* Literal.String.Single */
		.codehilite .ss { color: #87ceeb } /* Literal.String.Symbol */
		.codehilite .fm { color: #ffff00 } /* Name.Function.Magic */
		.codehilite .vc { color: #eedd82 } /* Name.Variable.Class */
		.codehilite .vg { color: #eedd82 } /* Name.Variable.Global */
		.codehilite .vi { color: #eedd82 } /* Name.Variable.Instance */
		.codehilite .vm { color: #eedd82 } /* Name.Variable.Magic */
	
</style>
<head>
  <meta charset="UTF-8">
</head>

<body><p>Poemas s√£o express√µes textuais. As vezes felizes, as vezes tristes; As vezes dif√≠ceis de compreender, as vezes t√£o simples quanto a mais simples das somas matem√°ticas. Poemas s√£o, em geral, express√µes sentimentais de algu√©m que prefere escrever √† aderir qualquer outro meio de express√£o art√≠stica.<br />
O mundo est√° repleto de poemas, e poemas est√£o repletos de um √∫nico fator comum:  <strong>Vida</strong>. Por algum motivo, alguma mente humana os deu um in√≠cio e um fim, com alguma finalidade, para que o possamos ler.  </p>
<blockquote>
<p>‚ÄúA vida √© a respira√ß√£o hipocondr√≠aca do mundo no cora√ß√£o. Ela me apaga, nunca √© s√≥. Ent√£o o mundo‚Ä¶ as estrelas‚Ä¶ que tanto tem ru√≠do √†s carnificinas que que julgamos t√£o pequenas: Linhas que nos levam √† um caminho. tinha uma pedra no meio do caminho tinha uma pedra no meio do ser.‚Ä  </p>
</blockquote>
<p><strong>Ao ler esta poesia, qual sentimento te abra√ßa?</strong>  </p>
<hr />
<p>Caso tenha reparado tra√ßos de algum(a) escritor nacional na poesia acima, voc√™ possui uma raz√£o parcial: O texto foi escrito por uma Rede Neural(Manualmente Adaptada e corrigida gramaticalmente) criada em  <strong>modelo sequencial</strong>, utilizando  <strong>entropia cruzada</strong>  e  <strong>mem√≥ria de longo prazo</strong>, tomando base em textos de escritores Brasileiros popularmente conhecidos.<br />
‚Äú_Teria um poema gerado por um computador algum prop√≥sito? Um prop√≥sito al√©m de o de ser gerado por um computador? Seriam as emo√ß√µes transmitidas por ele reais? A randomicidade inerente √† maquina tornaria a arte gerada por ela, a arte generativa, inferior ou menos sagrada_?‚Ä  </p>
<h1><strong>Rede Neural Artificial? O que √© isso?</strong></h1>
<p>Redes neurais artificiais(<strong>RNA</strong>) s√£o um conjunto de  <strong>algoritmos matem√°ticos</strong>, modelados vagamente por um  <strong>c√©rebro humano</strong>, projetados para  <strong>identificar padr√µes</strong>. Elas  <strong>interpretam</strong>  os dados sensoriais atrav√©s de um tipo de  <strong>percep√ß√£o da m√°quina</strong>, rotulando ou agrupando dados brutos. Os padr√µes que eles reconhecem s√£o  <strong>num√©ricos</strong>, e podem ser percept√≠veis √† qualquer dado do mundo real, sejam imagens, sons ou textos. Redes neurais Artificiais s√£o uma abstra√ß√£o da rede neural biol√≥gica. Seu objetivo n√£o √© replicar, mas sim servir de modelo para o aprendizado e resolu√ß√µes de problemas complexos.  </p>
<p><img alt="" src="https://miro.medium.com/max/393/1*K3kwICoLdrxczie-tYz7jQ.jpeg" />  </p>
<p>RNA model with math format  </p>
<h1>Neur√¥nios Artificiais? O que √© isso?</h1>
<p>Assim como no c√©rebro humano, os neur√¥nios artificiais possuem a miss√£o de transmitir informa√ß√µes.  </p>
<p><img alt="" src="https://miro.medium.com/max/828/1*lh5hiL8XKjMaWuWzauhnrQ.png" />  </p>
<p><strong>Imaginemos a seguinte situa√ß√£o</strong>: Queremos realizar uma previs√£o de pre√ßo de uma casa que est√° sendo construida em uma regi√£o  <strong>R</strong>  e que temos inten√ß√£o de comprar. Para isso, recolhemos dados de diversas casas que j√° existem na regi√£o, e estes dados s√£o ‚Äî Para fins de agilidade ‚Äî  <strong>Tamanho</strong>  e  <strong>pre√ßo</strong>.<br />
Portanto,  <strong>y = f(x)</strong>, o que significa que o pre√ßo da casa <strong>(y)</strong>  √© a fun√ß√£o do tamanho da casa  <strong>(x).</strong>  Vejamos em um gr√°fico:  </p>
<p><img alt="" src="https://miro.medium.com/max/1120/1*EpawrKOBRXp-cxbHDkah6A.png" />  </p>
<p>Agora, vamos desenhar uma linha reta usando esses dados no gr√°fico para visualizar a tend√™ncia dos dados.  </p>
<p><img alt="" src="https://miro.medium.com/max/1151/1*rNMcykuFM15g_12WR3IzAQ.png" /></p>
<p>Esta linha reta representa a tend√™ncia do pre√ßo das casas em rela√ß√£o aos seus respectivos tamanhos. Agora, Poodemos encontrar,  <strong>aproximadamente</strong>, o pre√ßo de qualquer casa desta regi√£o colocando-a nesse gr√°fico linear.<br />
E onde entram os neur√¥nios? Bem, como acabamos de ver, o tamanho da casa √© a  <strong>entrada</strong>  <strong>da</strong>  <strong>fun√ß√£o</strong>  <strong>(x)</strong>  e o pre√ßo √© a  <strong>sa√≠da (y)</strong>, e √© a√≠ que os  <strong>neur√¥nios artificiais</strong>  aparecem.<br />
<img alt="" src="https://miro.medium.com/max/478/1*HRXdKWUeMitbi5bludDxGg.jpeg" /></p>
<p>Esse √© o exemplo mais simples de uma rede neural, com uma √∫nica entrada, processamento e sa√≠da. Esse processamento, caso haja alguma d√∫vida, √© feito por fun√ß√µes matem√°ticas.<br />
Caso queiramos deixar as coisas mais interessantes, podemos adicionar outras vari√°veis de entrada, como  <strong>tamanho da fam√≠lia</strong>,  <strong>cep</strong>,  <strong>n√∫mero de quartos</strong>,  <strong>qualidade das escolas da redondeza</strong>  e a <strong>classe econ√¥mica da fam√≠lia</strong>. O resultado da interliga√ß√£o destas novas vari√°veis, seria algo mais ou menos assim: </p>
<p><img alt="" src="https://miro.medium.com/max/572/1*LOzkv1jwMh2JrKexkzJ7yg.png" /></p>
<h1><strong>Entropia cruzada? O que √© isso?</strong></h1>
<p><strong>Entropia</strong>  √© a medida do  <strong>grau de desordem</strong>  de um sistema, sendo uma medida da  <strong>indisponibilidade da energia</strong>.<br />
√â uma grandeza f√≠sica que est√° relacionada com a  <strong>Mec√¢nica Estat√≠stica</strong>  e com a  <strong>Segunda Lei da Termodin√¢mica</strong>, e que tende a aumentar naturalmente no Universo. A ‚Äú_desordem_‚Ä n√£o deve ser compreendida como ‚Äú_bagun√ßa_‚Ä e sim como a forma de organiza√ß√£o de sistema.<br />
<strong><em>Exemplo</em></strong>:<br />
<strong>Cubos de gelo derretendo,</strong>  antes de um cubo de gelo derreter, tem sua entropia menor, assim como seu  <strong>grau de desordem</strong>. Quando no estado s√≥lido, as dist√¢ncias intermoleculares eram  <strong>bem</strong>-<strong>definidas</strong>, bem como os √¢ngulos entre essas mol√©culas. Durante a  <strong>fus√£o</strong>  do gelo, ocorre um grande aumento na <strong>multiplicidade de dist√¢ncias e √¢ngulos</strong>  entre as mol√©culas, o que caracteriza o estado l√≠quido.  </p>
<hr />
<p>Na computa√ß√£o n√£o √© diferente! A Entropia √© uma medida da aleatoriedade de uma vari√°vel, e define a medida de ‚Äú_falta de informa√ß√£o_‚Ä, mais precisamente o n√∫mero de  <strong>bits</strong>  necess√°rios, em m√©dia, para representar a informa√ß√£o  <strong>em falta</strong>.<br />
Dado um conjunto  <strong>S</strong>, com inst√¢ncias pertencentes √† classe  <strong>I</strong>, com probabilidade  <strong>P(i)</strong>  , temos:<br />
<img alt="" src="https://miro.medium.com/max/442/1*WHf71OjjWUL8fkGG7rBXBg.png" /><br />
<img alt="" src="https://miro.medium.com/max/585/1*WUu58Q-zBTAJO5gSdHx2uA.png" /><br />
<strong>S</strong>  √© o conjunto de exemplo de treino,  <strong>p+</strong>  √© a por√ß√£o de exemplos positivos, <strong>p-</strong>  √© a por√ß√£o de exemplos negativos. Temos  <strong>Entropia(S) = 0</strong>  se existe um  <strong>i</strong>  tal que  <strong>P(i)</strong>  = 1 e assumido que  <strong>0 * log2 0 = 0.</strong><br />
Ela especifica o n√∫mero m√≠nimo de  <strong>bits</strong>  de  <strong>informa√ß√£o</strong>  necess√°rio para codificar uma classifica√ß√£o de um  <strong>membro arbitr√°rio</strong>  de  <strong>S</strong>.  </p>
<hr />
<p>Podemos classificar a  <strong>Entropia-Cruzada</strong>  como:<br />
<img alt="" src="https://miro.medium.com/max/301/1*ImtWFEVxsg78A5vK40D89A.png" /><br />
Onde  <strong>N</strong>  √© o n√∫mero de amostras,  <strong>M</strong>  √© o n√∫mero de camadas,  <strong>Sm</strong>  √© a dimens√£o de cada camada e  <strong>Y</strong>  s√£o as sa√≠das da rede.  </p>
<h1>Poesia Artificial</h1>
<p>Para nosso caso, utilizaremos uma base de dados(<strong>arquivo de texto</strong>) contendo diversas poesias. Caso voc√™ queira, pode utilizar seus escritos, ou os escritos de seus escritores prediletos. Quanto maior a quantidade e diversidade, melhor!  </p>
<h1>Keras</h1>
<p>√Äs palavras do pr√≥prio google, a Keras √© uma biblioteca de rede neural de c√≥digo aberto escrita em  <strong>Python</strong>(Linguagem de programa√ß√£o). √â capaz de rodar sobre  <strong>TensorFlow</strong>,  <strong>Microsoft Cognitive Toolkit</strong>,  <strong>R</strong>,  <strong>Theano</strong>  ou  <strong>PlaidML</strong>. Projetado para permitir experimenta√ß√£o r√°pida com redes neurais profundas, ele se concentra em ser f√°cil de usar, modular e extens√≠vel, e ela ser√° utilizada para cria√ß√£o do algoritmo.  </p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>  
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Bidirectional</span>  
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>  
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>  
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>  
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>  
<span class="kn">import</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">as</span> <span class="nn">ku</span>
</code></pre></div>


<h1>Tokenizing</h1>
<p>Ent√£o, o  <strong>tokenizer</strong>  basicamente permite a gente vetorizar todas as palavras dos poemas em nosso enorme  <strong>corpus</strong>  (arquivo de texto) em uma sequ√™ncia de n√∫meros inteiros ou vetores, o que pode ser √∫til para inserir na rede neural.  </p>
<div class="codehilite"><pre><span></span><code>tokenizer = Tokenizer()  
data = open(‚Äòpoesias.txt‚Äô,encoding=‚Äutf8&quot;).read()  
corpus = data.lower().split(‚Äú\n‚Ä)  
tokenizer.fit_on_texts(corpus)  
total_words = len(tokenizer.word_index) + 1**
</code></pre></div>


<p>Para um entendimento aprofundado do procedimento de tokenizing, eu recomendo este  <a href="https://www.youtube.com/watch?v=AcLKZg-GvxA">v√≠deo</a>.<br />
Ap√≥s vetorizadas, essas ser√£o as entradas dos nossos  <strong>Neur√¥nios Artificiais,</strong> No qual esperamos, na sa√≠da final, <strong>Uma Poesia.</strong>  </p>
<h1>Modelo de Constru√ß√£o</h1>
<p>O m√©todo sequencial no  <strong>Keras</strong>  √© o mais simples para criar um empilhamento de arquitetura de camadas, e √© ele que n√≥s vamos usar. O modelo sequencial nos permite inserir camadas de uma  <strong>Rede Neural Artificial</strong>  em s√©rie, onde a  <strong>sa√≠da</strong>  da primeira camada serve como  <strong>entrada</strong>  da segunda, e assim por diante, como visto acima no exemplo das casas com m√∫ltiplas vari√°veis.<br />
Tamb√©m usaremos  <strong>entropia cruzada categ√≥rica</strong>  como fun√ß√£o de perda e  <strong>Adam</strong>  (<a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#adam">Adaptive Moment Estimation</a>  )como otimizador.<br />
  ```
model = Sequential()<br />
model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))<br />
model.add(Bidirectional(LSTM(150, return_sequences = True)))<br />
model.add(Dropout(0.2))<br />
model.add(LSTM(100))<br />
model.add(Dense(total_words/2, activation=‚Äôrelu‚Äô, kernel_regularizer=regularizers.l2(0.01)))<br />
model.add(Dense(total_words, activation=‚Äôsoftmax‚Äô))<br />
model.compile(loss=‚Äôcategorical_crossentropy‚Äô, optimizer=‚Äôadam‚Äô, metrics=[‚Äòaccuracy‚Äô])<br />
print(model.summary())</p>
<div class="codehilite"><pre><span></span><code><span class="n">Depois</span><span class="w"> </span><span class="n">disso</span><span class="p">,</span><span class="w"> </span><span class="n">adicionamos</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">**</span><span class="n">camada</span><span class="w"> </span><span class="n">bidirecional</span><span class="o">**</span><span class="w"> </span><span class="o">[</span><span class="n">LSTM</span><span class="o">]</span><span class="p">(</span><span class="nl">https</span><span class="p">:</span><span class="o">//</span><span class="n">colah</span><span class="p">.</span><span class="n">github</span><span class="p">.</span><span class="n">io</span><span class="o">/</span><span class="n">posts</span><span class="o">/</span><span class="mi">2015</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="n">Understanding</span><span class="o">-</span><span class="n">LSTMs</span><span class="o">/</span><span class="p">)(</span><span class="n">_Long</span><span class="w"> </span><span class="n">short</span><span class="o">-</span><span class="n">term</span><span class="w"> </span><span class="n">memory</span><span class="p">)</span><span class="n">_</span><span class="w"> </span><span class="n">que</span><span class="w"> </span><span class="n">deixa</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">arquitetura</span><span class="w"> </span><span class="n">mais</span><span class="w"> </span><span class="n">ou</span><span class="w"> </span><span class="n">menos</span><span class="w"> </span><span class="nl">assim</span><span class="p">:</span><span class="w">  </span>
<span class="err">![]</span><span class="p">(</span><span class="nl">https</span><span class="p">:</span><span class="o">//</span><span class="n">miro</span><span class="p">.</span><span class="n">medium</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="nf">max</span><span class="o">/</span><span class="mi">395</span><span class="o">/</span><span class="mi">1</span><span class="o">*</span><span class="n">hDwEVtQqqiPtzyJrACbGTQ</span><span class="p">.</span><span class="n">jpeg</span><span class="p">)</span><span class="w">  </span>
<span class="n">E</span><span class="w"> </span><span class="n">ent√</span><span class="err">£</span><span class="n">o</span><span class="p">,</span><span class="w"> </span><span class="n">configuramos</span><span class="w"> </span><span class="n">uma</span><span class="w"> </span><span class="n">parte</span><span class="w"> </span><span class="n">mais</span><span class="w"> </span><span class="n">‚</span><span class="err">Ä</span><span class="n">úvisual‚</span><span class="err">Ä:</span><span class="w">  </span>
</code></pre></div>


<p>plt.plot(epochs, acc, ‚Äòb‚Äô, label=‚ÄôTraining accuracy‚Äô)<br />
plt.title(‚ÄòTraining accuracy‚Äô)<br />
plt.figure()<br />
plt.plot(epochs, loss, ‚Äòb‚Äô, label=‚ÄôTraining Loss‚Äô)<br />
plt.title(‚ÄòTraining loss‚Äô)<br />
plt.legend()<br />
plt.show()</p>
<div class="codehilite"><pre><span></span><code>Essa parte nos ajuda √† visualizar, graficamente, o desempenho da nossa  **Rede Neural Artificial**, para saber se esta flui com bom desempenho no aprendizado.  
# Hora de Redigir!  
</code></pre></div>


<p>seed_text = ‚ÄúA vida √© uma‚Ä<br />
next_words = 50  </p>
<p>for _ in range(next_words):<br />
 token_list = tokenizer.texts_to_sequences([seed_text])[0]<br />
 token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding=‚Äôpre‚Äô)<br />
 predicted = model.predict_classes(token_list, verbose=0)<br />
 output_word = ‚Äú‚Ä<br />
 for word, index in tokenizer.word_index.items():<br />
 if index == predicted:<br />
 output_word = word<br />
 break<br />
 seed_text += ‚Äú ‚Äú + output_word<br />
print(seed_text)
```  </p>
<p>‚Äú<strong>seed_text</strong>‚Ä √© um ‚Äú_gatilho_‚Ä para nossa Rede Neural. √â com base nela que tudo vai come√ßar √† ser escrito. E ‚Äú<strong>next_words</strong>‚Ä serve para especificar quantas palavras deseja que ele escreva. E, ap√≥s tudo isso, basta rodar o c√≥digo e ver nosso  <strong>Poeta Mec√¢nico</strong>  agir. E ent√£o, cabe a voc√™ julgar a sa√≠da e interpretar, sentimentalmente ou n√£o, a express√£o de uma m√°quina.</p>
<p>Al√©m da sa√≠da feita com escritores nacionais, esse √© um exemplo de sa√≠da de testes com poemas feitos por escritores internacionais:</p>
<blockquote>
<p>What is this life converge in a late to depart blue years day a moon in little years putting putting i was blue without my victories day a ragtag bell without day a moon to our cache years the letters snaps blue day a moon day day they were never best friends into the</p>
</blockquote>
<p>Lembrando que</p>
<p><strong>o objetivo n√£o √© a perfei√ß√£o</strong>, e pode n√£o ter tanto sentido nas primeiras tentativas. Mas, nada que tempo e ajustes manuais de gram√°tica e pontua√ß√£o n√£o resolvam. Claro, tamb√©m √© poss√≠vel corrigir os pr√≥prios erros utilizando Redes Neurais Artificiais, mas essa eu vou deixar para um pr√≥ximo dia.</p>
<p>O c√≥digo completo pode ser encontrado <a href="https://github.com/agrawalparth08/poetry-generation-lstm/blob/master/Poetry_Generation.ipynb">aqui</a>, e uma explica√ß√£o aprofundada no primeiro link nas refer√™ncias.<br />
Para fins de estudo e divers√£o, recomendo a publica√ß√£o de  <a href="https://medium.com/caio-noobs-around/p3ss04-utilizando-cadeias-de-markov-e-algoritmo-gen%C3%A9tico-para-a-gera%C3%A7%C3%A3o-de-poemas-generativos-caeed388dd0a">caioluders</a>  onde ele utiliza um m√©todo alternativo e super interessante para escrever poesias. Saca l√°!</p>
<h2>Refer√™ncias:</h2>
<p>TOWARDSDC ‚Äî  <a href="https://towardsdatascience.com/creating-poems-from-ones-own-poems-neural-networks-and-life-paradoxes-a9cffd2b07e3">CREATING POEMS FROM ONE OWN POEMS</a><br />
TOWARDSDC ‚Äî <a href="https://towardsdatascience.com/creating-poems-from-ones-own-poems-neural-networks-and-life-paradoxes-a9cffd2b07e3">WHAT‚ÄôS A NEURAL NETWORK?</a><br />
REDES NEURAIS ARTIFICIAIS ‚Äî CAPITULO2.PDF  </p></body><hr>by cnx</html>